- 图像识别 -> **CNN卷积神经网络**
- NLP自然语言处理 -> **RNN循环神经网络** 解决了seq2seq问题 输入输出语句长短不同
- Transformer与RNN都保留了**编码和解码**的结构
## 词嵌入
- “码”指的大概是 把语言中的形式的不同去除后，剩下的单纯的**语义关系**，其标准有：

1. 数字化
2. 数值体现语义之间的相对关系


> 对token进行数字化的两种极端情况，上述的第一点标准都能实现，但第二点都是极端的错误：

- **tokenizer标记器**（分词器）：每一个token都是不同的ID（一维）
- **onehot独热编码**：每一个token是二级制中的每一位（n维）

> 矩阵乘法实现词嵌入，编码进潜空间，解码出潜空间

- **潜空间**：没有形式上差别的语义空间，是连续的，因此遇到陌生的情况也能找到对应的值

## Word2Vec（词典）

> 一般的机器学习目标：得到一个模型，模型能够完成任务；**Word2Vec**得到的是嵌入矩阵，得到的是模型的参数

- Word2Vec**不需要激活函数**，隐藏层输出层的神经元做的就是向量求和与分解，没有非线性的需求

> 编码解码的过程大概是：输入token，经过矩阵编码得到词向量，而后解码再变成Token

- CBOW和skip-gram都是**自监督**的方法，前者根据上下文中的词来预测目标词，后者相反

## Transformer
### 注意力


